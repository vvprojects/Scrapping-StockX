{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193aeeae-addd-4b23-8626-4863370e23ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configure retry strategy for robust downloads\n",
    "retry_strategy = Retry(\n",
    "    total=3,\n",
    "    backoff_factor=1,\n",
    "    status_forcelist=[429, 500, 502, 503, 504],\n",
    "    allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    ")\n",
    "\n",
    "# Create session with headers and retries\n",
    "session = requests.Session()\n",
    "session.mount('https://', HTTPAdapter(max_retries=retry_strategy))\n",
    "session.headers.update({\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8',\n",
    "    'Referer': 'https://www.stockx.com/'\n",
    "})\n",
    "\n",
    "# Initialize ResNet model once (more efficient)\n",
    "model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Enhanced data preprocessing pipeline\"\"\"\n",
    "    # Extract retail price\n",
    "    price_pattern = r'(?:retail|price|at)\\s*\\$?(\\d{2,3})(?:\\.\\d{2})?'\n",
    "    df['retail_price'] = df['description'].str.extract(price_pattern, flags=re.IGNORECASE)[0].astype(float)\n",
    "    \n",
    "    # Handle release dates\n",
    "    df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "    df['release_year'] = df['release_date'].dt.year.fillna(-1).astype(int)\n",
    "    df['release_month'] = df['release_date'].dt.month.fillna(-1).astype(int)\n",
    "    df['release_dayofweek'] = df['release_date'].dt.dayofweek.fillna(-1).astype(int)\n",
    "    \n",
    "    # Encode categorical features\n",
    "    df = pd.get_dummies(df, columns=['brand', 'product_category'], \n",
    "                       prefix=['brand', 'category'], dummy_na=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_image(url):\n",
    "    \"\"\"Robust image processing with error handling\"\"\"\n",
    "    try:\n",
    "        response = session.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "            \n",
    "        return img.resize((224, 224))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Image download failed: {url} - {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def extract_features(url):\n",
    "    \"\"\"CNN feature extraction with fallback\"\"\"\n",
    "    img = process_image(url)\n",
    "    if img is None:\n",
    "        return np.zeros(2048)  # Return zero array for missing images\n",
    "    \n",
    "    try:\n",
    "        # Convert to array and preprocess\n",
    "        img_array = np.array(img)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        \n",
    "        # Extract features\n",
    "        features = model.predict(img_array, verbose=0)\n",
    "        return features.flatten()\n",
    "    except Exception as e:\n",
    "        print(f\"Feature extraction failed: {url} - {str(e)}\")\n",
    "        return np.zeros(2048)\n",
    "\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv('third_version_of_stockx_data_with_kinda_many_brands_without_dropping_nan_description.csv')\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    # Extract features with progress\n",
    "    print(\"Extracting image features...\")\n",
    "    tqdm.pandas(desc=\"Processing images\")\n",
    "    df['cnn_features'] = df['thumb_url'].progress_apply(extract_features)\n",
    "    \n",
    "    # Convert features to storage-friendly format\n",
    "    df['cnn_features'] = df['cnn_features'].apply(\n",
    "        lambda x: ';'.join(map(str, x)) if isinstance(x, np.ndarray) else ';'.join(map(str, np.zeros(2048))))\n",
    "    \n",
    "    # Save results\n",
    "    print(\"Saving results...\")\n",
    "    df.to_csv('stockx_with_cnn_features.csv', index=False)\n",
    "    print(\"Processing complete! Saved to stockx_with_cnn_features.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
